[
    {
        "title": "AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis",
        "summary": "The collection of large-scale and diverse robot demonstrations remains a major bottleneck for imitation learning, as real-world data acquisition is costly and simulators offer limited diversity and fidelity with pronounced sim-to-real gaps. While generative models present an attractive solution, existing methods often alter only visual appearances without creating new behaviors, or suffer from embodiment inconsistencies that yield implausible motions. To address these limitations, we introduce AnchorDream, an embodiment-aware world model that repurposes pretrained video diffusion models for robot data synthesis. AnchorDream conditions the diffusion process on robot motion renderings, anchoring the embodiment to prevent hallucination while synthesizing objects and environments consistent with the robot's kinematics. Starting from only a handful of human teleoperation demonstrations, our method scales them into large, diverse, high-quality datasets without requiring explicit environment modeling. Experiments show that the generated data leads to consistent improvements in downstream policy learning, with relative gains of 36.4% in simulator benchmarks and nearly double performance in real-world studies. These results suggest that grounding generative world models in robot motion provides a practical path toward scaling imitation learning.",
        "url": "http://arxiv.org/abs/2512.11797v1",
        "published_date": "2025-12-12T18:59:45+00:00",
        "updated_date": "2025-12-12T18:59:45+00:00",
        "categories": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Junjie Ye",
            "Rong Xue",
            "Basile Van Hoorick",
            "Pavel Tokmakov",
            "Muhammad Zubair Irshad",
            "Yue Wang",
            "Vitor Guizilini"
        ],
        "tldr": "AnchorDream uses video diffusion models conditioned on robot motion renderings to generate large, diverse, and high-quality robot datasets from limited human teleoperation demonstrations, significantly improving downstream policy learning in both simulation and real-world settings.",
        "tldr_zh": "AnchorDream通过视频扩散模型，以机器人运动渲染为条件，从少量人类遥操作演示中生成大量、多样化和高质量的机器人数据集，从而显著提高模拟和实际环境中的下游策略学习。",
        "relevance_score": 9,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9,
        "summary_zh": "大规模且多样化的机器人演示数据的收集仍然是模仿学习的主要瓶颈，因为真实世界的数据获取成本高昂，而模拟器提供的多样性和保真度有限，且存在显著的“模拟到真实”差距。 虽然生成模型提供了一个有吸引力的解决方案，但现有方法通常只改变视觉外观而不创造新的行为，或者遭受具身不一致性，从而导致不可思议的运动。 为了解决这些限制，我们引入了AnchorDream，一种具身感知的世界模型，它将预训练的视频扩散模型重新用于机器人数据合成。 AnchorDream 将扩散过程限制在机器人运动渲染上，锚定具身以防止幻觉，同时合成与机器人运动学一致的物体和环境。 仅仅从少量的真人遥操作演示开始，我们的方法就可以将它们扩展为大型、多样化、高质量的数据集，而无需显式的环境建模。 实验表明，生成的数据在下游策略学习中带来了一致的改进，在模拟器基准测试中相对增益为 36.4%，在真实世界研究中性能几乎翻倍。 这些结果表明，将生成世界模型建立在机器人运动的基础上，为扩展模仿学习提供了一条可行的途径。"
    },
    {
        "title": "BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models",
        "summary": "Vision-language-action (VLA) models enable impressive zero shot manipulation, but their inference stacks are often too heavy for responsive web demos or high frequency robot control on commodity GPUs. We present BLURR, a lightweight inference wrapper that can be plugged into existing VLA controllers without retraining or changing model checkpoints. Instantiated on the pi-zero VLA controller, BLURR keeps the original observation interfaces and accelerates control by combining an instruction prefix key value cache, mixed precision execution, and a single step rollout schedule that reduces per step computation. In our SimplerEnv based evaluation, BLURR maintains task success rates comparable to the original controller while significantly lowering effective FLOPs and wall clock latency. We also build an interactive web demo that allows users to switch between controllers and toggle inference options in real time while watching manipulation episodes. This highlights BLURR as a practical approach for deploying modern VLA policies under tight compute budgets.",
        "url": "http://arxiv.org/abs/2512.11769v1",
        "published_date": "2025-12-12T18:30:45+00:00",
        "updated_date": "2025-12-12T18:30:45+00:00",
        "categories": [
            "cs.RO"
        ],
        "authors": [
            "Xiaoyu Ma",
            "Zhengqing Yuan",
            "Zheyuan Zhang",
            "Kaiwen Shi",
            "Lichao Sun",
            "Yanfang Ye"
        ],
        "tldr": "BLURR is a lightweight inference wrapper for VLA models that significantly reduces computation and latency without retraining, enabling deployment on resource-constrained platforms.",
        "tldr_zh": "BLURR是一个轻量级的VLA模型推理封装器，无需重新训练即可显著降低计算量和延迟，从而能够在资源受限的平台上进行部署。",
        "relevance_score": 10,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 9,
        "overall_priority_score": 9,
        "summary_zh": "视觉-语言-动作 (VLA) 模型实现了令人印象深刻的零样本操作，但其推理堆栈通常过于庞大，难以在商品级 GPU 上实现响应迅速的网络演示或高频机器人控制。我们提出了 BLURR，一个轻量级的推理封装器，可以插入到现有的 VLA 控制器中，而无需重新训练或更改模型检查点。BLURR 在 pi-zero VLA 控制器上实例化，保留了原始观察接口，并通过结合指令前缀键值缓存、混合精度执行和单步展开调度来加速控制，从而减少每步计算量。在基于 SimplerEnv 的评估中，BLURR 在保持与原始控制器相当的任务成功率的同时，显著降低了有效 FLOPs 和实际延迟。我们还构建了一个交互式网络演示，允许用户在观看操作过程的同时，实时切换控制器和切换推理选项。 这突显了 BLURR 是在有限计算预算下部署现代 VLA 策略的一种实用方法。"
    },
    {
        "title": "Agile Flight Emerges from Multi-Agent Competitive Racing",
        "summary": "Through multi-agent competition and the sparse high-level objective of winning a race, we find that both agile flight (e.g., high-speed motion pushing the platform to its physical limits) and strategy (e.g., overtaking or blocking) emerge from agents trained with reinforcement learning. We provide evidence in both simulation and the real world that this approach outperforms the common paradigm of training agents in isolation with rewards that prescribe behavior, e.g., progress on the raceline, in particular when the complexity of the environment increases, e.g., in the presence of obstacles. Moreover, we find that multi-agent competition yields policies that transfer more reliably to the real world than policies trained with a single-agent progress-based reward, despite the two methods using the same simulation environment, randomization strategy, and hardware. In addition to improved sim-to-real transfer, the multi-agent policies also exhibit some degree of generalization to opponents unseen at training time. Overall, our work, following in the tradition of multi-agent competitive game-play in digital domains, shows that sparse task-level rewards are sufficient for training agents capable of advanced low-level control in the physical world.\n  Code: https://github.com/Jirl-upenn/AgileFlight_MultiAgent",
        "url": "http://arxiv.org/abs/2512.11781v1",
        "published_date": "2025-12-12T18:48:50+00:00",
        "updated_date": "2025-12-12T18:48:50+00:00",
        "categories": [
            "cs.RO",
            "cs.AI",
            "cs.MA"
        ],
        "authors": [
            "Vineet Pasumarti",
            "Lorenzo Bianchi",
            "Antonio Loquercio"
        ],
        "tldr": "This paper demonstrates that agile flight and strategic behaviors emerge in multi-agent drone racing through reinforcement learning with a sparse, win-based reward, outperforming methods using dense, progress-based rewards, and exhibiting better sim-to-real transfer and generalization.",
        "tldr_zh": "该论文展示了通过强化学习和稀疏的胜负奖励，多智能体无人机竞速可以涌现出敏捷飞行和策略性行为。这种方法优于使用密集、基于进度的奖励的方法，并表现出更好的从模拟到现实的迁移和泛化能力。",
        "relevance_score": 8,
        "novelty_claim_score": 7,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 8,
        "summary_zh": "通过多智能体竞争以及赢得比赛的稀疏高层目标，我们发现敏捷飞行（例如，将平台推向物理极限的高速运动）和策略（例如，超车或阻挡）都从使用强化学习训练的智能体中涌现出来。我们提供的仿真和真实世界证据表明，该方法优于常见的在隔离环境中训练智能体并使用规定行为的奖励（例如，在赛道上的进展）的范式，尤其是在环境复杂性增加时（例如，存在障碍物时）。此外，我们发现，尽管两种方法使用相同的仿真环境、随机化策略和硬件，但多智能体竞争产生的策略比使用基于单智能体进展的奖励训练的策略更可靠地迁移到真实世界。除了改进的仿真到真实世界迁移之外，多智能体策略还表现出一定程度的泛化能力，能够适应训练期间未曾见过的对手。总而言之，我们的工作延续了数字领域多智能体竞争游戏的传统，表明稀疏的任务级奖励足以训练能够在物理世界中进行高级底层控制的智能体。\n代码：https://github.com/Jirl-upenn/AgileFlight_MultiAgent"
    },
    {
        "title": "ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics",
        "summary": "Monocular depth estimation (MDE) provides a useful tool for robotic perception, but its predictions are often uncertain and inaccurate in challenging environments such as surgical scenes where textureless surfaces, specular reflections, and occlusions are common. To address this, we propose ProbeMDE, a cost-aware active sensing framework that combines RGB images with sparse proprioceptive measurements for MDE. Our approach utilizes an ensemble of MDE models to predict dense depth maps conditioned on both RGB images and on a sparse set of known depth measurements obtained via proprioception, where the robot has touched the environment in a known configuration. We quantify predictive uncertainty via the ensemble's variance and measure the gradient of the uncertainty with respect to candidate measurement locations. To prevent mode collapse while selecting maximally informative locations to propriocept (touch), we leverage Stein Variational Gradient Descent (SVGD) over this gradient map. We validate our method in both simulated and physical experiments on central airway obstruction surgical phantoms. Our results demonstrate that our approach outperforms baseline methods across standard depth estimation metrics, achieving higher accuracy while minimizing the number of required proprioceptive measurements.",
        "url": "http://arxiv.org/abs/2512.11773v1",
        "published_date": "2025-12-12T18:36:53+00:00",
        "updated_date": "2025-12-12T18:36:53+00:00",
        "categories": [
            "cs.RO"
        ],
        "authors": [
            "Britton Jordan",
            "Jordan Thompson",
            "Jesse F. d'Almeida",
            "Hao Li",
            "Nithesh Kumar",
            "Susheela Sharma Stern",
            "Ipek Oguz",
            "Robert J. Webster",
            "Daniel Brown",
            "Alan Kuntz",
            "James Ferguson"
        ],
        "tldr": "This paper introduces ProbeMDE, a method for improving monocular depth estimation in surgical robotics by using uncertainty-guided active proprioception to strategically select locations for sparse depth measurements, leading to more accurate and efficient depth estimation.",
        "tldr_zh": "本文介绍了ProbeMDE，一种通过不确定性引导的主动本体感觉来选择稀疏深度测量位置，从而提高手术机器人单目深度估计的方法，从而实现更准确和高效的深度估计。",
        "relevance_score": 7,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 7,
        "summary_zh": "单目深度估计 (MDE) 为机器人感知提供了一种有用的工具，但其预测结果在具有挑战性的环境中往往存在不确定性和不准确性，例如手术场景中常见的无纹理表面、镜面反射和遮挡。为了解决这个问题，我们提出了 ProbeMDE，一种具有成本意识的主动感知框架，它将 RGB 图像与稀疏的本体感受测量结合用于 MDE。我们的方法利用一个 MDE 模型集成，来预测以 RGB 图像和通过本体感受获得的稀疏已知深度测量集为条件的密集深度图，其中机器人以已知配置触摸环境。我们通过集成的方差来量化预测的不确定性，并测量不确定性相对于候选测量位置的梯度。为了在选择最具信息量的本体感受 (触摸) 位置时防止模式崩塌，我们利用基于该梯度图的 Stein 变分梯度下降 (SVGD)。我们在中央气道阻塞手术模型上的模拟和物理实验中验证了我们的方法。我们的结果表明，我们的方法在标准深度估计指标上优于基线方法，并在最小化所需本体感受测量次数的同时实现了更高的精度。"
    },
    {
        "title": "Particulate: Feed-Forward 3D Object Articulation",
        "summary": "We present Particulate, a feed-forward approach that, given a single static 3D mesh of an everyday object, directly infers all attributes of the underlying articulated structure, including its 3D parts, kinematic structure, and motion constraints. At its core is a transformer network, Part Articulation Transformer, which processes a point cloud of the input mesh using a flexible and scalable architecture to predict all the aforementioned attributes with native multi-joint support. We train the network end-to-end on a diverse collection of articulated 3D assets from public datasets. During inference, Particulate lifts the network's feed-forward prediction to the input mesh, yielding a fully articulated 3D model in seconds, much faster than prior approaches that require per-object optimization. Particulate can also accurately infer the articulated structure of AI-generated 3D assets, enabling full-fledged extraction of articulated 3D objects from a single (real or synthetic) image when combined with an off-the-shelf image-to-3D generator. We further introduce a new challenging benchmark for 3D articulation estimation curated from high-quality public 3D assets, and redesign the evaluation protocol to be more consistent with human preferences. Quantitative and qualitative results show that Particulate significantly outperforms state-of-the-art approaches.",
        "url": "http://arxiv.org/abs/2512.11798v1",
        "published_date": "2025-12-12T18:59:51+00:00",
        "updated_date": "2025-12-12T18:59:51+00:00",
        "categories": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "authors": [
            "Ruining Li",
            "Yuxin Yao",
            "Chuanxia Zheng",
            "Christian Rupprecht",
            "Joan Lasenby",
            "Shangzhe Wu",
            "Andrea Vedaldi"
        ],
        "tldr": "Particulate is a feed-forward transformer network that infers the articulation of 3D objects from a single static mesh, outperforming existing methods in speed and accuracy, and enabling articulation extraction from AI-generated 3D assets.",
        "tldr_zh": "Particulate是一个前馈Transformer网络，可以从单个静态网格推断3D物体的关节，在速度和准确性方面优于现有方法，并能够从AI生成的3D资产中提取关节。",
        "relevance_score": 4,
        "novelty_claim_score": 8,
        "clarity_score": 9,
        "potential_impact_score": 7,
        "overall_priority_score": 6,
        "summary_zh": "我们提出了Particulate，一种前馈方法，它在给定日常物体的单个静态3D网格的情况下，直接推断底层铰接结构的所有属性，包括其3D部件、运动学结构和运动约束。其核心是一个Transformer网络，即部件铰接Transformer，它使用灵活且可扩展的架构处理输入网格的点云，以预测所有上述属性，并原生支持多关节。我们在来自公共数据集的各种铰接3D资源集合上对网络进行端到端训练。在推理过程中，Particulate将网络的馈入预测提升到输入网格，从而在几秒钟内生成一个完全铰接的3D模型，比先前需要对每个对象进行优化的方法快得多。Particulate还可以准确推断AI生成的3D资产的铰接结构，当与现成的图像到3D生成器结合使用时，能够从单个图像（真实或合成）中全面提取铰接的3D对象。我们还引入了一个新的具有挑战性的3D铰接估计基准，该基准是从高质量的公共3D资产中整理出来的，并重新设计了评估协议，使其与人类偏好更加一致。定量和定性结果表明，Particulate明显优于最先进的方法。"
    },
    {
        "title": "Toward a Decision Support System for Energy-Efficient Ferry Operation on Lake Constance based on Optimal Control",
        "summary": "The maritime sector is undergoing a disruptive technological change driven by three main factors: autonomy, decarbonization, and digital transformation. Addressing these factors necessitates a reassessment of inland vessel operations. This paper presents the design and development of a decision support system for ferry operations based on a shrinking-horizon optimal control framework. The problem formulation incorporates a mathematical model of the ferry's dynamics and environmental disturbances, specifically water currents and wind, which can significantly influence the dynamics. Real-world data and illustrative scenarios demonstrate the potential of the proposed system to effectively support ferry crews by providing real-time guidance. This enables enhanced operational efficiency while maintaining predefined maneuver durations. The findings suggest that optimal control applications hold substantial promise for advancing future ferry operations on inland waters. A video of the real-world ferry MS Insel Mainau operating on Lake Constance is available at: https://youtu.be/i1MjCdbEQyE",
        "url": "http://arxiv.org/abs/2512.11786v1",
        "published_date": "2025-12-12T18:55:22+00:00",
        "updated_date": "2025-12-12T18:55:22+00:00",
        "categories": [
            "eess.SY",
            "cs.HC",
            "cs.RO"
        ],
        "authors": [
            "Hannes Homburger",
            "Bastian Jäckl",
            "Stefan Wirtensohn",
            "Christian Stopp",
            "Maximilian T. Fischer",
            "Moritz Diehl",
            "Daniel A. Keim",
            "Johannes Reuter"
        ],
        "tldr": "This paper presents a decision support system for energy-efficient ferry operation on Lake Constance, using a shrinking-horizon optimal control framework to provide real-time guidance to ferry crews.",
        "tldr_zh": "本文介绍了一个为康斯坦茨湖上的节能渡轮运营设计的决策支持系统，该系统使用一个收缩范围的最优控制框架，为渡轮船员提供实时指导。",
        "relevance_score": 2,
        "novelty_claim_score": 5,
        "clarity_score": 8,
        "potential_impact_score": 6,
        "overall_priority_score": 4,
        "summary_zh": "航运业正经历一场由自主化、脱碳化和数字化转型这三大因素驱动的颠覆性技术变革。应对这些因素需要重新评估内河船舶运营。本文介绍了一种基于收缩时域最优控制框架的渡轮运营决策支持系统的设计与开发。该问题公式化纳入了渡轮动力学和环境扰动的数学模型，特别是水流和风，它们会显著影响动力学。真实数据和示例场景证明了所提出的系统在实时指导方面有效支持渡轮船员的潜力。这能够在维持预定义的机动持续时间的同时，提高运营效率。研究结果表明，最优控制应用在推进未来内河水域渡轮运营方面具有巨大的前景。关于在康斯坦茨湖运营的真实渡轮MS Insel Mainau的视频可在以下网址观看：https://youtu.be/i1MjCdbEQyE"
    }
]